{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAPER REVIEW AND IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),  # 원래 이미지는 HxWxC 이지만, ToTensor를 사용하면 CxHxW로 변환된다.\n",
    "     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))] # 3개의 채널에 대해 각각 mean, std를 설정해준다. 0~255 -> -1~1 0.5를 기준으로 정규분포\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = { \"A\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "         \"B\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "         \"D\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"],\n",
    "         \"E\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256, \"M\", 512, 512, 512, 512, \"M\", 512, 512, 512, 512, \"M\"] }\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, cfg, batch_norm, num_class=1000, init_weights = True, drop_p = 0.5):\n",
    "        super().__init__() # nn.module 상속\n",
    "    \n",
    "        self.features = self.make_layers(cfg, batch_norm)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7,7)) # avgpooling 인데 그냥 적응형으로 intput에 상관 없이 output size를 7x7로 만들어줌\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512*7*7, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_p),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_p),\n",
    "            nn.Linear(4096, num_class)\n",
    "        )\n",
    "        \n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode = 'fan_out', nonlinearity = 'relu')\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "                    elif isinstance(m, nn.Linear):\n",
    "                        nn.init.normal_(m.weight, 0, 0.01)\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)  # feature map 추출\n",
    "        x = self.avgpool(x)   # avgpooling\n",
    "        x = torch.flatten(x, 1)  # 1차원으로 펴줌\n",
    "        x = self.classifier(x)  # fc layer\n",
    "        return x\n",
    "    \n",
    "    def make_layers(self, cfg, batch_norm = False):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for v in cfg:\n",
    "            if type(v) == int:\n",
    "                if batch_norm:\n",
    "                    layers += [nn.Conv2d(in_channels, v, 3, padding=1),\n",
    "                               nn.BatchNorm2d(v),\n",
    "                               nn.ReLU()]\n",
    "                else:\n",
    "                    layers += [nn.Conv2d(in_channels, v, 3, padding=1), \n",
    "                               nn.ReLU()]\n",
    "                in_channels = v\n",
    "            else:\n",
    "                layers += [nn.MaxPool2d(2,2)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VGG                                      [2, 1000]                 --\n",
       "├─Sequential: 1-1                        [2, 512, 7, 7]            --\n",
       "│    └─Conv2d: 2-1                       [2, 64, 224, 224]         1,792\n",
       "│    └─ReLU: 2-2                         [2, 64, 224, 224]         --\n",
       "│    └─Conv2d: 2-3                       [2, 64, 224, 224]         36,928\n",
       "│    └─ReLU: 2-4                         [2, 64, 224, 224]         --\n",
       "│    └─MaxPool2d: 2-5                    [2, 64, 112, 112]         --\n",
       "│    └─Conv2d: 2-6                       [2, 128, 112, 112]        73,856\n",
       "│    └─ReLU: 2-7                         [2, 128, 112, 112]        --\n",
       "│    └─Conv2d: 2-8                       [2, 128, 112, 112]        147,584\n",
       "│    └─ReLU: 2-9                         [2, 128, 112, 112]        --\n",
       "│    └─MaxPool2d: 2-10                   [2, 128, 56, 56]          --\n",
       "│    └─Conv2d: 2-11                      [2, 256, 56, 56]          295,168\n",
       "│    └─ReLU: 2-12                        [2, 256, 56, 56]          --\n",
       "│    └─Conv2d: 2-13                      [2, 256, 56, 56]          590,080\n",
       "│    └─ReLU: 2-14                        [2, 256, 56, 56]          --\n",
       "│    └─Conv2d: 2-15                      [2, 256, 56, 56]          590,080\n",
       "│    └─ReLU: 2-16                        [2, 256, 56, 56]          --\n",
       "│    └─Conv2d: 2-17                      [2, 256, 56, 56]          590,080\n",
       "│    └─ReLU: 2-18                        [2, 256, 56, 56]          --\n",
       "│    └─MaxPool2d: 2-19                   [2, 256, 28, 28]          --\n",
       "│    └─Conv2d: 2-20                      [2, 512, 28, 28]          1,180,160\n",
       "│    └─ReLU: 2-21                        [2, 512, 28, 28]          --\n",
       "│    └─Conv2d: 2-22                      [2, 512, 28, 28]          2,359,808\n",
       "│    └─ReLU: 2-23                        [2, 512, 28, 28]          --\n",
       "│    └─Conv2d: 2-24                      [2, 512, 28, 28]          2,359,808\n",
       "│    └─ReLU: 2-25                        [2, 512, 28, 28]          --\n",
       "│    └─Conv2d: 2-26                      [2, 512, 28, 28]          2,359,808\n",
       "│    └─ReLU: 2-27                        [2, 512, 28, 28]          --\n",
       "│    └─MaxPool2d: 2-28                   [2, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-29                      [2, 512, 14, 14]          2,359,808\n",
       "│    └─ReLU: 2-30                        [2, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-31                      [2, 512, 14, 14]          2,359,808\n",
       "│    └─ReLU: 2-32                        [2, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-33                      [2, 512, 14, 14]          2,359,808\n",
       "│    └─ReLU: 2-34                        [2, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-35                      [2, 512, 14, 14]          2,359,808\n",
       "│    └─ReLU: 2-36                        [2, 512, 14, 14]          --\n",
       "│    └─MaxPool2d: 2-37                   [2, 512, 7, 7]            --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [2, 512, 7, 7]            --\n",
       "├─Sequential: 1-3                        [2, 1000]                 --\n",
       "│    └─Linear: 2-38                      [2, 4096]                 102,764,544\n",
       "│    └─ReLU: 2-39                        [2, 4096]                 --\n",
       "│    └─Dropout: 2-40                     [2, 4096]                 --\n",
       "│    └─Linear: 2-41                      [2, 4096]                 16,781,312\n",
       "│    └─ReLU: 2-42                        [2, 4096]                 --\n",
       "│    └─Dropout: 2-43                     [2, 4096]                 --\n",
       "│    └─Linear: 2-44                      [2, 1000]                 4,097,000\n",
       "==========================================================================================\n",
       "Total params: 143,667,240\n",
       "Trainable params: 143,667,240\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 39.29\n",
       "==========================================================================================\n",
       "Input size (MB): 1.20\n",
       "Forward/backward pass size (MB): 237.78\n",
       "Params size (MB): 574.67\n",
       "Estimated Total Size (MB): 813.65\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG(cfgs[\"E\"], batch_norm=False)\n",
    "\n",
    "summary(model, input_size=(2,3,224,224), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [07:22<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     output \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     13\u001b[0m     loss \u001b[39m=\u001b[39m criterion(output,y_)\n\u001b[0;32m---> 14\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     15\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/implementation/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/implementation/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()  #손실함수\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # optimizer\n",
    "num_epochs = 10\n",
    "loss_arr = []\n",
    "\n",
    "for i in trange(num_epochs):\n",
    "    for n,(image,label) in enumerate(trainloader, 0):\n",
    "        x = image.to(device)\n",
    "        y_ = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output,y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if i % 10 == 0:\n",
    "        print(loss)\n",
    "        loss_arr.append(loss.cpu().detach().numpy())    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "implementation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
